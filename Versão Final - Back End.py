{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafeadb-ffc4-4c07-b963-b054ccb56be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import FAISS  # or Chroma/Pinecone\n",
    "import csv\n",
    "from docx import Document\n",
    "from langchain_chroma import Chroma  # or FAISS, Pinecone, etc.\n",
    "import pandas as pd\n",
    "import logging\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a6942-9df8-4ec4-9eea-67216c97fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the existing functions are defined as provided\n",
    "def extract_paragraphs(docx_path):\n",
    "    print(docx_path)\n",
    "    try:\n",
    "        if not os.path.exists(docx_path):\n",
    "            raise FileNotFoundError(f\"File not found: {docx_path}\")\n",
    "        \n",
    "        doc = Document(docx_path)\n",
    "        paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]\n",
    "        return paragraphs\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(fnf_error)\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the file: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d405a5d-ee43-4c84-9e12-9d6bb36cd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_segment_paragraphs(paragraph_list, openai_api_key, model_name=\"gpt-4\", batch_size=5):\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"combined_paragraphs\"],\n",
    "        template=\"\"\"\n",
    "        You're a precise legal AI assistant. Segment each provided NDA paragraph into numbered clauses.\n",
    "\n",
    "        RULES TO STRICTLY FOLLOW:\n",
    "        - Do NOT paraphrase or change wording.\n",
    "        - Copy clauses EXACTLY as provided.\n",
    "        - ONLY segment into numbered clauses without edits.\n",
    "\n",
    "        {combined_paragraphs}\n",
    "\n",
    "        Format strictly as follows:\n",
    "\n",
    "        Paragraph 1:\n",
    "        1. [Clause copied EXACTLY]\n",
    "        2. [Clause copied EXACTLY]\n",
    "\n",
    "        Paragraph 2:\n",
    "        1. [Clause copied EXACTLY]\n",
    "        2. [Clause copied EXACTLY]\n",
    "\n",
    "        If you paraphrase or modify any wording, the answer is incorrect.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=model_name,\n",
    "        openai_api_key=openai_api_key,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    all_clauses = []\n",
    "    total_paragraphs = len(paragraph_list)\n",
    "\n",
    "    for start_idx in range(0, total_paragraphs, batch_size):\n",
    "        batch_paragraphs = paragraph_list[start_idx : start_idx + batch_size]\n",
    "\n",
    "        combined_paragraphs = \"\\n\\n\".join([\n",
    "            f\"Paragraph {start_idx + idx + 1}: {paragraph}\"\n",
    "            for idx, paragraph in enumerate(batch_paragraphs)\n",
    "        ])\n",
    "\n",
    "        response = chain.run(combined_paragraphs=combined_paragraphs).strip()\n",
    "\n",
    "        # Parsing the response clearly using regex\n",
    "        paragraph_splits = re.split(r'\\n\\s*Paragraph\\s+\\d+:\\s*\\n', \"\\n\" + response.strip())\n",
    "\n",
    "        # The first split element can be empty, remove it\n",
    "        if paragraph_splits[0].strip() == \"\":\n",
    "            paragraph_splits = paragraph_splits[1:]\n",
    "\n",
    "        for para_text in paragraph_splits:\n",
    "            clauses = []\n",
    "            for line in para_text.strip().split(\"\\n\"):\n",
    "                match = re.match(r\"^\\s*\\d+[.\\-)]\\s*(.*)$\", line.strip())\n",
    "                if match:\n",
    "                    clauses.append(match.group(1).strip())\n",
    "            all_clauses.append(clauses)\n",
    "\n",
    "    return all_clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d0b3d-7f02-42ae-8a0f-50c99ae38aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_rewrite_clauses(\n",
    "    new_paragraphs,\n",
    "    vectordb,\n",
    "    df_historical,\n",
    "    openai_api_key,\n",
    "    standard_dict,\n",
    "    top_original,\n",
    "    top_standard,\n",
    "    classification_threshold=0.2,\n",
    "    rewrite_threshold=0.65,\n",
    "    fuzzy_cutoff=0.75,\n",
    "    similarity_cutoff = 0.3\n",
    "):\n",
    "    \"\"\"\n",
    "    1) For each clause in `new_paragraphs`, classify it by searching entire vectordb (any source).\n",
    "    2) If classification found, gather up to top_original (3) from source=\"original\" with same classification,\n",
    "       then fuzzy-match these originals to the historical DataFrame to find their 'Final Clause'.\n",
    "    3) Also gather top_standard (5) from source=\"standard\" with the same classification.\n",
    "    4) Pass everything to GPT to produce a final rewriting if needed.\n",
    "    5) Return a DataFrame with columns [\"new_clause\", \"final_version\", \"classification\"].\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup the rewriting prompt\n",
    "    rewrite_prompt = PromptTemplate(\n",
    "        input_variables=[\"new_clause\", \"historical_pairs\", \"standard_refs\", \"classification_label\", \"similarity_score\"],\n",
    "        template=\"\"\"\n",
    "You are a legal AI. We have received a paragraph of NDA (below).\n",
    "We also have 2 reference modifications from our history and a standard clause.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Compare clauses**: compare the received clause with the standard and original references.\n",
    "\n",
    "2. **Identify Differences**: Determine whether there are significant differences in legally relevant terms, meaning, or structure. Focus on clauses related to:\n",
    "- Definition of \"Affiliates\", \"Persons\" and \"Representatives\" must closely match ours\n",
    "- Eligible Court must be Rio de Janeiro\n",
    "- Governing Law must be Brazilian Law \n",
    "- Duration must be one or two years\n",
    "\n",
    "3. **Identify Similarities**: Determine where are the similarities between the clause being revised and the original historical clause given as reference.\n",
    "\n",
    "4. **Modify clauses**: Adjust clauses that differ notably to align with the NDA standard. Use the historical references to learn how should the modification be done.\n",
    "\n",
    "Approximate similarity to best clause in history = {similarity_score}\n",
    "Your changes may include deleting the clause as a whole or parts of it when deemed necessary.\n",
    "\n",
    "4. **Produce revised NDA**: Provide the revised clause without commentary or reasoning, ensuring a professional format for legal review. Be as concise and brief as possible. Try to keep the wording of the original clause as close as possible.\n",
    "\n",
    "The final clause should be presented coherently, maintaining a professional style without additional commentary. Even if several changes are made, try to keep the revised clause as close to the original as possible. Use the historical clauses only as a general reference, without using specific names or references.\n",
    "\n",
    "New paragraph:\n",
    "{new_clause}\n",
    "\n",
    "Top historical examples of how it was previously done:\n",
    "{historical_pairs}\n",
    "\n",
    "Standard clauses\n",
    "{standard_refs}\n",
    "\n",
    "Notes:\n",
    "When rewriting, keep an eye on the context of the reference text, and if it is similar to the clause being revised. Look to keep the new clause as close as possible to the original.\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    llm_model = ChatOpenAI(\n",
    "        model_name=\"ft:gpt-4o-mini-2024-07-18:opportunity::BDYO66Nj\",\n",
    "        openai_api_key=openai_api_key,\n",
    "        temperature=0.0,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    chain_rewrite = LLMChain(llm=llm_model, prompt=rewrite_prompt)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for new_clause in new_paragraphs:\n",
    "        # --- Step 1: Classification\n",
    "        docs_and_scores = vectordb.similarity_search_with_score(new_clause, k=1)\n",
    "        if not docs_and_scores:\n",
    "            # If no match, mark unclassified\n",
    "            results.append({\n",
    "                \"new_clause\": new_clause,\n",
    "                \"classification\": \"unclassified\",\n",
    "                \"final_version\": new_clause\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        best_doc, best_score = docs_and_scores[0]\n",
    "        sim = 1 - best_score\n",
    "        if sim >= classification_threshold:\n",
    "            classification_label = best_doc.metadata.get(\"classification\", \"unclassified\")\n",
    "        else:\n",
    "            classification_label = \"unclassified\"\n",
    "\n",
    "        # If unclassified => skip rewriting\n",
    "        if classification_label == \"unclassified\":\n",
    "            results.append({\n",
    "                \"new_clause\": new_clause,\n",
    "                \"classification\": classification_label,\n",
    "                \"final_version\": new_clause\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # --- Step 2A: Retrieve top original from the DB\n",
    "\n",
    "        filter_ori = {\n",
    "            \"$and\": [\n",
    "                {\"classification\": {\"$eq\": classification_label}},\n",
    "                {\"source\": {\"$eq\": \"original\"}}\n",
    "            ]\n",
    "        }\n",
    "        docs_original = vectordb.similarity_search_with_score(\n",
    "            new_clause,\n",
    "            k=30,  # increase to ensure enough good results\n",
    "            filter=filter_ori\n",
    "        )\n",
    "        filter_rev = {\n",
    "            \"$and\": [\n",
    "                {\"classification\": {\"$eq\": classification_label}},\n",
    "                {\"source\": {\"$eq\": \"revised\"}}\n",
    "            ]\n",
    "        }\n",
    "        docs_revised = vectordb.similarity_search_with_score(\n",
    "            new_clause,\n",
    "            k=30,  # increase to ensure enough good results\n",
    "            filter=filter_rev\n",
    "        )\n",
    "        all_docs_and_scores = docs_original + docs_revised\n",
    "        \n",
    "        # Filter out below similarity cutoff\n",
    "        filtered_docs = [(doc, score) for doc, score in all_docs_and_scores if 1 - score >= similarity_cutoff]\n",
    "        \n",
    "        # Sort and select top-N\n",
    "        filtered_docs.sort(key=lambda x: x[1])  # ascending distance\n",
    "        top_docs = filtered_docs[:top_original]\n",
    "\n",
    "        # Build the historical pairs string\n",
    "        historical_pairs_str = \"\"\n",
    "        if top_docs:\n",
    "            for rank, (doc, score_val) in enumerate(top_docs, start=1):\n",
    "                sim_val = 1 - score_val\n",
    "                matched_text = doc.page_content\n",
    "                source_type = doc.metadata.get(\"source\", \"\")\n",
    "                \n",
    "                # Fuzzy matching logic\n",
    "                if source_type == \"original\":\n",
    "                    # Try to find a fuzzy match in the Initial Clause column\n",
    "                    all_inits = df_historical[\"Initial Clause\"].dropna().tolist()\n",
    "                    best_match = difflib.get_close_matches(matched_text, all_inits, n=1, cutoff=fuzzy_cutoff)\n",
    "                    if best_match:\n",
    "                        row = df_historical[df_historical[\"Initial Clause\"] == best_match[0]]\n",
    "                        revised_text = row[\"Final Clause\"].iloc[0] if not row.empty else \"[Revised not found]\"\n",
    "                        matched_text = best_match[0]  # optionally use matched version\n",
    "                    else:\n",
    "                        revised_text = \"[No fuzzy match found]\"\n",
    "                    \n",
    "                    historical_pairs_str += (\n",
    "                        f\"\\nOriginal #{rank} (sim={sim_val:.2f}): {matched_text}\"\n",
    "                        f\"\\nRevised #{rank}: {revised_text}\\n\"\n",
    "                    )\n",
    "                \n",
    "                elif source_type == \"revised\":\n",
    "                    # Try to find a fuzzy match in the Final Clause column\n",
    "                    all_revised = df_historical[\"Final Clause\"].dropna().tolist()\n",
    "                    best_match = difflib.get_close_matches(matched_text, all_revised, n=1, cutoff=fuzzy_cutoff)\n",
    "                    if best_match:\n",
    "                        row = df_historical[df_historical[\"Final Clause\"] == best_match[0]]\n",
    "                        original_text = row[\"Initial Clause\"].iloc[0] if not row.empty else \"[Original not found]\"\n",
    "                        matched_text = best_match[0]  # optionally use matched version\n",
    "                    else:\n",
    "                        original_text = \"[No fuzzy match found]\"\n",
    "                \n",
    "                    historical_pairs_str += (f\"\\nRevised #{rank} (sim={sim_val:.2f}): {matched_text}\"f\"\\nOriginal #{rank}: {original_text}\\n\"\n",
    "                                            )\n",
    "        else:\n",
    "            historical_pairs_str = \"No historical original clauses found for this classification.\"\n",
    "\n",
    "        # --- Step 2B: Retrieve top standard\n",
    "        filter_std = {\n",
    "            \"$and\": [\n",
    "                {\"classification\": {\"$eq\": classification_label}},\n",
    "                {\"source\": {\"$eq\": \"standard\"}}\n",
    "            ]\n",
    "        }\n",
    "        all_standard_docs_and_scores = vectordb.similarity_search_with_score(\n",
    "            new_clause,\n",
    "            k=20,\n",
    "            filter=filter_std\n",
    "        )\n",
    "        # 2) Filter out below similarity_cutoff\n",
    "        filtered_standard_docs = []\n",
    "        for doc, distance in all_standard_docs_and_scores:\n",
    "            sim = 1 - distance\n",
    "            if sim >= 0.2:\n",
    "                filtered_standard_docs.append((doc, distance))\n",
    "\n",
    "        # 3) Now sort them by best similarity (lowest distance)\n",
    "        filtered_standard_docs.sort(key=lambda x: x[1])  # distance ascending\n",
    "\n",
    "        # 4) Finally, take the top_original from the filtered set\n",
    "        top_standard_docs_and_scores = filtered_standard_docs[:top_standard]\n",
    "        standard_refs_str = \"\"\n",
    "        if top_standard_docs_and_scores:\n",
    "            for rank, (doc, score_val) in enumerate(top_standard_docs_and_scores, start=1):\n",
    "                sim_val = 1 - score_val\n",
    "                std_text = doc.page_content\n",
    "                standard_refs_str += f\"\\nStandard #{rank} (sim={sim_val:.2f}): {std_text}\\n\"\n",
    "        else:\n",
    "            standard_refs_str = \"-\"\n",
    "\n",
    "        # --- Step 3: Rewriting logic\n",
    "        if sim < rewrite_threshold:\n",
    "            # rewrite\n",
    "            response = chain_rewrite.run(\n",
    "                new_clause=new_clause,\n",
    "                historical_pairs=historical_pairs_str.strip(),\n",
    "                standard_refs=standard_refs_str.strip(),\n",
    "                classification_label=classification_label,\n",
    "                similarity_score=f\"{sim:.2f}\"\n",
    "            )\n",
    "            final_version = response.strip()\n",
    "        else:\n",
    "            # keep as-is if similarity is high\n",
    "            final_version = new_clause\n",
    "\n",
    "        results.append({\n",
    "            \"new_clause\": new_clause,\n",
    "            \"classification\": classification_label,\n",
    "            \"final_version\": final_version,\n",
    "            \"histórico\": historical_pairs_str,\n",
    "            \"padrão\": standard_refs_str\n",
    "        })\n",
    "\n",
    "    # convert to DataFrame\n",
    "    df_out = pd.DataFrame(results, columns=[\"new_clause\", \"final_version\", \"classification\",\"histórico\",\"padrão\"])\n",
    "    return df_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python nda_env",
   "language": "python",
   "name": "nda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
